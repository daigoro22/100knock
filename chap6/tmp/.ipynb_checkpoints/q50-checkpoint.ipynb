{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   about    after  all       and  are        as   at  bank   be  before  ...  \\\n",
      "0    0.0  0.00000  0.0  0.000000  0.0  0.000000  0.0   0.0  0.0     0.0  ...   \n",
      "1    0.0  0.31646  0.0  0.000000  0.0  0.000000  0.0   0.0  0.0     0.0  ...   \n",
      "2    0.0  0.00000  0.0  0.000000  0.0  0.000000  0.0   0.0  0.0     0.0  ...   \n",
      "3    0.0  0.00000  0.0  0.000000  0.0  0.000000  0.0   0.0  0.0     0.0  ...   \n",
      "4    0.0  0.00000  0.0  0.463099  0.0  0.439275  0.0   0.0  0.0     0.0  ...   \n",
      "\n",
      "   wall  wall st  was  week  west  who  will  with  year  you  \n",
      "0   0.0      0.0  0.0   0.0   0.0  0.0   0.0   0.0   0.0  0.0  \n",
      "1   0.0      0.0  0.0   0.0   0.0  0.0   0.0   0.0   0.0  0.0  \n",
      "2   0.0      0.0  0.0   0.0   0.0  0.0   0.0   0.0   0.0  0.0  \n",
      "3   0.0      0.0  0.0   0.0   0.0  0.0   0.0   0.0   0.0  0.0  \n",
      "4   0.0      0.0  0.0   0.0   0.0  0.0   0.0   0.0   0.0  0.0  \n",
      "\n",
      "[5 rows x 111 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import string\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def preprocessing(text):\n",
    "    table = str.maketrans(string.punctuation, ' '*len(string.punctuation))\n",
    "    text = text.translate(table)  # 記号をスペースに置換\n",
    "    text = text.lower()  # 小文字化\n",
    "    text = re.sub('[0-9]+', '0', text)  # 数字列を0に置\n",
    "    return text\n",
    "\n",
    "# データの読込\n",
    "df = pd.read_csv('newsCorpora.csv', header=None, sep='\\t', names=['ID', 'TITLE', 'URL', 'PUBLISHER', 'CATEGORY', 'STORY', 'HOSTNAME', 'TIMESTAMP'])\n",
    "\n",
    "# データの抽出\n",
    "df = df.loc[df['PUBLISHER'].isin(['Reuters', 'Huffington Post', 'Businessweek', 'Contactmusic.com', 'Daily Mail']), ['TITLE', 'CATEGORY']]\n",
    "\n",
    "# データの分割\n",
    "train, valid_test = train_test_split(df, test_size=0.2, shuffle=True, random_state=123, stratify=df['CATEGORY'])\n",
    "valid, test = train_test_split(valid_test, test_size=0.5, shuffle=True, random_state=123, stratify=valid_test['CATEGORY'])\n",
    "\n",
    "# 事例数の確認\n",
    "#print('学習データ')\n",
    "#print(train['CATEGORY'].value_counts())\n",
    "#print('検証データ')\n",
    "#print(valid['CATEGORY'].value_counts())\n",
    "#print('評価データ')\n",
    "#print(test['CATEGORY'].value_counts())\n",
    "\n",
    "# データの再結合\n",
    "df = pd.concat([train, valid, test], axis=0)\n",
    "df.reset_index(drop=True, inplace=True)  # indexを振りなおす\n",
    "\n",
    "# 前処理の実施\n",
    "df['TITLE'] = df['TITLE'].map(lambda x: preprocessing(x))\n",
    "\n",
    "#print(df.head())\n",
    "\n",
    "train_valid = df[:len(train) + len(valid)]\n",
    "test = df[len(train) + len(valid):]\n",
    "\n",
    "# TfidfVectorizer\n",
    "vec_tfidf = TfidfVectorizer(min_df=0.01, ngram_range=(1, 2))  # ngram_rangeでTF-IDFを計算する単語の長さを指定\n",
    "\n",
    "# ベクトル化\n",
    "X_train_valid = vec_tfidf.fit_transform(train_valid['TITLE'])  # testの情報は使わない\n",
    "X_test = vec_tfidf.transform(test['TITLE'])\n",
    "\n",
    "# ベクトルをデータフレームに変換\n",
    "X_train_valid = pd.DataFrame(X_train_valid.toarray(), columns=vec_tfidf.get_feature_names())\n",
    "X_test = pd.DataFrame(X_test.toarray(), columns=vec_tfidf.get_feature_names())\n",
    "\n",
    "# データの分割\n",
    "X_train = X_train_valid[:len(train)]\n",
    "X_valid = X_train_valid[len(train):]\n",
    "\n",
    "# データの保存\n",
    "X_train.to_csv('./X_train.txt', sep='\\t', index=False,header=False)\n",
    "X_valid.to_csv('./X_valid.txt', sep='\\t', index=False,header=False)\n",
    "X_test.to_csv('./X_test.txt', sep='\\t', index=False,header=False)\n",
    "\n",
    "print(X_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
